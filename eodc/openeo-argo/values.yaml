# Default values for openeo-argo.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.
global:
  env:
    alembicDir: "/opt/openeo_argoworkflows_api/psql"
    apiDns: 127.0.0.1:8000
    apiTLS: false
    apiTitle: "OpenEO ArgoWorkflows"
    apiDescription: "A K8S deployment of the openeo api for argoworkflows."
    oidcUrl: "https://aai.egi.eu/auth/realms/egi"
    odicOrganisation: "egi"
    oidcPolicies: ""
    stacCatalogueUrl: "https://stac.eodc.eu/api/v1"
    workspaceRoot: "/user_workspaces"
    executorImage: "ghcr.io/eodcgmbh/openeo-argoworkflows:executor-2025.5.1"
    daskWorkerCores: "4"
    daskWorkerMemory: "8"
    daskWorkerLimit: "6"
    daskClusterTimeout: "3600" 

replicaCount: 1

labels: {}

image:
  repository: ghcr.io/eodcgmbh/openeo-argoworkflows
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: "api-2025.5.1"

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Automatically mount a ServiceAccount's API credentials?
  automount: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podAnnotations: {}
podLabels: {}

persistence:
    
    existingVolume: ""

    capacity: "8Gi"

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

service:
  type: ClusterIP
  port: 8000

ingress:
  enabled: false
  className: ""
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

livenessProbe:
  httpGet:
    path: /.well-known/openeo/
    port: http
readinessProbe:
  httpGet:
    path: /.well-known/openeo/
    port: http

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

# Additional volumes on the output Deployment definition.
volumes: []
# - name: foo
#   secret:
#     secretName: mysecret
#     optional: false

# Additional volumeMounts on the output Deployment definition.
volumeMounts: []
# - name: foo
#   mountPath: "/etc/foo"
#   readOnly: true

nodeSelector: {}

tolerations: []

affinity: {}


postgresql:

  enabled: true

  image:
    repository: bitnamilegacy/postgresql

  service:
    ports:
      postgresql: "5432"

  clusterDomain: "cluster.local"


argoworkflows:

  enabled: true

  singleNamespace: true


redis:

  image:
    repository: bitnamilegacy/redis

  auth:
    enabled: false

  replica:
  
    replicaCount: 1

dask-gateway:

  enabled: true

  # Do not change this configuration for dask gateway when enabling dask gateway.
  # For an existing dask gateway installation, the user-workspace volume would need to be available
  # to the worker pods, and the extra cluster options need to be present.
  gateway:

    backend:
    
      worker:
        
        extraPodConfig: 
          volumes:
            - name: user-workspace
              persistentVolumeClaim:
                claimName: openeo-workspace

        extraContainerConfig: 
          volumeMounts:
            - name: user-workspace
              mountPath: "/user_workspaces"


    extraConfig: 
      optionHandler: |
        from dask_gateway_server.options import Options, Integer, Float, String
        def option_handler(options):
          return {
              "worker_cores": options.WORKER_CORES,
              "worker_memory": "%fG" % options.WORKER_MEMORY,
              "scheduler_extra_pod_labels": {'OPENEO_USER_ID': options.OPENEO_USER_ID, 'OPENEO_JOB_ID': options.OPENEO_JOB_ID },
              "worker_extra_pod_labels": {'OPENEO_USER_ID': options.OPENEO_USER_ID, 'OPENEO_JOB_ID': options.OPENEO_JOB_ID },
              "idle_timeout": options.CLUSTER_IDLE_TIMEOUT,
              "image": options.IMAGE
          }

        c.Backend.cluster_options = Options(
            Integer("WORKER_CORES", 4, min=1, max=12, label="Worker Cores"),
            Float("WORKER_MEMORY", 12, min=1, max=24, label="Worker Memory (GiB)"),
            String("OPENEO_USER_ID", "Unassigned", label="User identifier"),
            String("OPENEO_JOB_ID", "Unassigned", label="Job identifier"),
            Float("CLUSTER_IDLE_TIMEOUT", 3600, label="Idle Timeout"),
            String("IMAGE", "ghcr.io/dask/dask-gateway:2024.1.0", label="Worker image"),
            handler=option_handler,
        )

  traefik:

    service:
      type: ClusterIP
